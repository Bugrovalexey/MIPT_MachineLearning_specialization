{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия и стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание основано на материалах лекций по линейной регрессии и градиентному спуску. Вы будете прогнозировать выручку компании в зависимости от уровня ее инвестиций в рекламу по TV, в газетах и по радио."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вы научитесь:\n",
    "- решать задачу восстановления линейной регрессии\n",
    "- реализовывать стохастический градиентный спуск для ее настройки\n",
    "- решать задачу линейной регрессии аналитически"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "Линейная регрессия - один из наиболее хорошо изученных методов машинного обучения, позволяющий прогнозировать значения количественного признака в виде линейной комбинации прочих признаков с параметрами - весами модели. Оптимальные (в смысле минимальности некоторого функционала ошибки) параметры линейной регрессии можно найти аналитически с помощью нормального уравнения или численно с помощью методов оптимизации.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия использует простой функционал качества - среднеквадратичную ошибку. Мы будем работать с выборкой, содержащей 3 признака. Для настройки параметров (весов) модели решается следующая задача:\n",
    "$$\\Large \\frac{1}{\\ell}\\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}^2} \\rightarrow \\min_{w_0, w_1, w_2, w_3},$$\n",
    "где $x_{i1}, x_{i2}, x_{i3}$ - значения признаков $i$-го объекта, $y_i$ - значение целевого признака $i$-го объекта, $\\ell$ - число объектов в обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск\n",
    "Параметры $w_0, w_1, w_2, w_3$, по которым минимизируется среднеквадратичная ошибка, можно находить численно с помощью градиентного спуска.\n",
    "Градиентный шаг для весов будет выглядеть следующим образом:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{x_{ij}((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}},\\ j \\in \\{1,2,3\\}$$\n",
    "Здесь $\\eta$ - параметр, шаг градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастический градиентный спуск\n",
    "Проблема градиентного спуска, описанного выше, в том, что на больших выборках считать на каждом шаге градиент по всем имеющимся данным может быть очень вычислительно сложно. \n",
    "В стохастическом варианте градиентного спуска поправки для весов вычисляются только с учетом одного случайно взятого объекта обучающей выборки:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} {((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} {x_{kj}((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)},\\ j \\in \\{1,2,3\\},$$\n",
    "где $k$ - случайный индекс, $k \\in \\{1, \\ldots, \\ell\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормальное уравнение \n",
    "Нахождение вектора оптимальных весов $w$ может быть сделано и аналитически.\n",
    "Мы хотим найти такой вектор весов $w$, чтобы вектор $y$, приближающий целевой признак, получался умножением матрицы $X$ (состоящей из всех признаков объектов обучающей выборки, кроме целевого) на вектор весов $w$. То есть, чтобы выполнялось матричное уравнение:\n",
    "$$\\Large y = Xw$$\n",
    "Домножением слева на $X^T$ получаем:\n",
    "$$\\Large X^Ty = X^TXw$$\n",
    "Это хорошо, поскольку теперь матрица $X^TX$ - квадратная, и можно найти решение (вектор $w$) в виде:\n",
    "$$\\Large w = {(X^TX)}^{-1}X^Ty$$\n",
    "Матрица ${(X^TX)}^{-1}X^T$ - [*псевдообратная*](https://ru.wikipedia.org/wiki/Псевдообратная_матрица) для матрицы $X$. В NumPy такую матрицу можно вычислить с помощью функции [numpy.linalg.pinv](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.linalg.pinv.html).\n",
    "\n",
    "Однако, нахождение псевдообратной матрицы - операция вычислительно сложная и нестабильная в случае малого определителя матрицы $X$ (проблема мультиколлинеарности). \n",
    "На практике лучше находить вектор весов $w$ решением матричного уравнения \n",
    "$$\\Large X^TXw = X^Ty$$Это может быть сделано с помощью функции [numpy.linalg.solve](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.linalg.solve.html).\n",
    "\n",
    "Но все же на практике для больших матриц $X$ быстрее работает градиентный спуск, особенно его стохастическая версия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкции по выполнению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В начале напишем простую функцию для записи ответов в текстовый файл. Ответами будут числа, полученные в ходе решения этого задания, округленные до 3 знаков после запятой. Полученные файлы после выполнения задания надо отправить в форму на странице задания на Coursera.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_answer_to_file(answer, filename):\n",
    "    with open(\"submissions/\" + filename, 'w') as f_out:\n",
    "        f_out.write(str(round(answer, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Загрузите данные из файла *advertising.csv* в объект pandas DataFrame. [Источник данных](http://www-bcf.usc.edu/~gareth/ISL/data.html).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "adver_data = pd.read_csv('data/advertising.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Посмотрите на первые 5 записей и на статистику признаков в этом наборе данных.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "1  230.1   37.8       69.2   22.1\n",
       "2   44.5   39.3       45.1   10.4\n",
       "3   17.2   45.9       69.3    9.3\n",
       "4  151.5   41.3       58.5   18.5\n",
       "5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adver_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>147.042500</td>\n",
       "      <td>23.264000</td>\n",
       "      <td>30.554000</td>\n",
       "      <td>14.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>85.854236</td>\n",
       "      <td>14.846809</td>\n",
       "      <td>21.778621</td>\n",
       "      <td>5.217457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.375000</td>\n",
       "      <td>9.975000</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>10.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>149.750000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>12.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>218.825000</td>\n",
       "      <td>36.525000</td>\n",
       "      <td>45.100000</td>\n",
       "      <td>17.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>296.400000</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TV       Radio   Newspaper       Sales\n",
       "count  200.000000  200.000000  200.000000  200.000000\n",
       "mean   147.042500   23.264000   30.554000   14.022500\n",
       "std     85.854236   14.846809   21.778621    5.217457\n",
       "min      0.700000    0.000000    0.300000    1.600000\n",
       "25%     74.375000    9.975000   12.750000   10.375000\n",
       "50%    149.750000   22.900000   25.750000   12.900000\n",
       "75%    218.825000   36.525000   45.100000   17.400000\n",
       "max    296.400000   49.600000  114.000000   27.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adver_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создайте массивы NumPy *X* из столбцов TV, Radio и Newspaper и *y* - из столбца Sales. Используйте атрибут *values* объекта pandas DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = adver_data[['TV', 'Radio', 'Newspaper']].values\n",
    "y = adver_data['Sales'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отмасштабируйте столбцы матрицы *X*, вычтя из каждого значения среднее по соответствующему столбцу и поделив результат на стандартное отклонение. Для определенности, используйте методы mean и std векторов NumPy (реализация std в Pandas может отличаться). Обратите внимание, что в numpy вызов функции .mean() без параметров возвращает среднее по всем элементам массива, а не по столбцам, как в pandas. Чтобы произвести вычисление по столбцам, необходимо указать параметр axis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 147.0425   23.264    30.554 ]\n",
      "[ 85.63933176  14.80964564  21.72410606]\n"
     ]
    }
   ],
   "source": [
    "means, stds = X.mean(axis=0), X.std(axis=0)\n",
    "print(means)\n",
    "print(stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ох и не нравится мне мутировать предыдущие перменные, \n",
    "# нужно же все строчик в ноутбуке делать идемпотентными!\n",
    "# >_<\n",
    "X = (X - means) / stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавьте к матрице *X* столбец из единиц, используя методы *hstack*, *ones* и *reshape* библиотеки NumPy. Вектор из единиц нужен для того, чтобы не обрабатывать отдельно коэффициент $w_0$ линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ones = np.ones(len(X)).reshape((X.shape[0], 1))\n",
    "X = np.hstack([X, ones])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Реализуйте функцию *mserror* - среднеквадратичную ошибку прогноза. Она принимает два аргумента - объекты Series *y* (значения целевого признака) и *y\\_pred* (предсказанные значения). Не используйте в этой функции циклы - тогда она будет вычислительно неэффективной.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mserror(y, y_pred):\n",
    "    return sum((y - y_pred)**2) / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales, если всегда предсказывать медианное значение Sales по исходной выборке? Запишите ответ в файл '1.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.34575\n"
     ]
    }
   ],
   "source": [
    "pred_median = np.ones(y.shape) * np.median(y)\n",
    "answer1 = mserror(y, pred_median)\n",
    "print(answer1)\n",
    "write_answer_to_file(answer1, '1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Реализуйте функцию *normal_equation*, которая по заданным матрицам (массивам NumPy) *X* и *y* вычисляет вектор весов $w$ согласно нормальному уравнению линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normal_equation(X, y):\n",
    "    return np.dot(np.linalg.pinv(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
      "Wall time: 9.06 µs\n",
      "[  3.91925365   2.79206274  -0.02253861  14.0225    ]\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "norm_eq_weights = normal_equation(X, y)\n",
    "print(norm_eq_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какие продажи предсказываются линейной моделью с весами, найденными с помощью нормального уравнения, в случае средних инвестиций в рекламу по ТВ, радио и в газетах? (то есть при нулевых значениях масштабированных признаков TV, Radio и Newspaper). Запишите ответ в файл '2.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.0225\n"
     ]
    }
   ],
   "source": [
    "answer2 = np.dot([0,0,0,1],norm_eq_weights)\n",
    "print(answer2)\n",
    "write_answer_to_file(answer2, '2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Напишите функцию *linear_prediction*, которая принимает на вход матрицу *X* и вектор весов линейной модели *w*, а возвращает вектор прогнозов в виде линейной комбинации столбцов матрицы *X* с весами *w*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_prediction(X, w):\n",
    "    return np.dot(X, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью нормального уравнения? Запишите ответ в файл '3.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.78412631451\n"
     ]
    }
   ],
   "source": [
    "answer3 = mserror(y, linear_prediction(X, norm_eq_weights))\n",
    "print(answer3)\n",
    "write_answer_to_file(answer3, '3.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Напишите функцию *stochastic_gradient_step*, реализующую шаг стохастического градиентного спуска для линейной регрессии. Функция должна принимать матрицу *X*, вектора *y* и *w*, число *train_ind* - индекс объекта обучающей выборки (строки матрицы *X*), по которому считается изменение весов, а также число *$\\eta$* (eta) - шаг градиентного спуска (по умолчанию *eta*=0.01). Результатом будет вектор обновленных весов. Наша реализация функции будет явно написана для данных с 3 признаками, но несложно модифицировать для любого числа признаков, можете это сделать.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.91925365,   2.79206274,  -0.02253861,  14.0225    ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_eq_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_step(X, y, w, train_ind, eta=0.01):\n",
    "    return  w + 2 * eta * X[train_ind] * (y[train_ind] - X[train_ind].dot(w)) / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Напишите функцию *stochastic_gradient_descent*, реализующую стохастический градиентный спуск для линейной регрессии. Функция принимает на вход следующие аргументы:**\n",
    "- X - матрица, соответствующая обучающей выборке\n",
    "- y - вектор значений целевого признака\n",
    "- w_init - вектор начальных весов модели\n",
    "- eta - шаг градиентного спуска (по умолчанию 0.01)\n",
    "- max_iter - максимальное число итераций градиентного спуска (по умолчанию 10000)\n",
    "- max_weight_dist - минимальное евклидово расстояние между векторами весов на соседних итерациях градиентного спуска,\n",
    "при котором алгоритм прекращает работу (по умолчанию 1e-8)\n",
    "- seed - число, используемое для воспроизводимости сгенерированных псевдослучайных чисел (по умолчанию 42)\n",
    "- verbose - флаг печати информации (например, для отладки, по умолчанию False)\n",
    "\n",
    "**На каждой итерации в вектор (список) должно записываться текущее значение среднеквадратичной ошибки. Функция должна возвращать вектор весов $w$, а также вектор (список) ошибок.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, y, w_init, eta=1e-2, max_iter=1e4,\n",
    "                                min_weight_dist=1e-8, seed=42, verbose=False):\n",
    "    # Инициализируем расстояние между векторами весов на соседних\n",
    "    # итерациях большим числом. \n",
    "    weight_dist = np.inf\n",
    "    # Инициализируем вектор весов\n",
    "    w = w_init\n",
    "    # Сюда будем записывать ошибки на каждой итерации\n",
    "    errors = []\n",
    "    # Счетчик итераций\n",
    "    iter_num = 0\n",
    "    # Будем порождать псевдослучайные числа \n",
    "    # (номер объекта, который будет менять веса), а для воспроизводимости\n",
    "    # этой последовательности псевдослучайных чисел используем seed.\n",
    "    np.random.seed(seed)\n",
    "        \n",
    "    # Основной цикл\n",
    "    while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "        # порождаем псевдослучайный \n",
    "        # индекс объекта обучающей выборки\n",
    "        random_ind = np.random.randint(X.shape[0])\n",
    "        \n",
    "        # добавляем значение ошики предсказания на текущем векторе коэффициентов W\n",
    "        errors.append(mserror(y, linear_prediction(X, w)))\n",
    "        w_new = stochastic_gradient_step(X, y, w, random_ind)\n",
    "        # вычисляем на сколько изменился вектор W после очередного шага градиентного спуска\n",
    "        weight_dist = np.linalg.norm(w_new - w)\n",
    "        # обновляем коэффициенты и шагаем дальше\n",
    "        w = w_new\n",
    "        iter_num += 1\n",
    "        \n",
    "    return w, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Запустите $10^5$ итераций стохастического градиентного спуска. Укажите вектор начальных весов *w_init*, состоящий из нулей. Оставьте параметры  *eta* и *seed* равными их значениям по умолчанию (*eta*=0.01, *seed*=42 - это важно для проверки ответов).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.92 s, sys: 80 ms, total: 6 s\n",
      "Wall time: 6.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stoch_grad_desc_weights, stoch_errors_by_iter = stochastic_gradient_descent(X, y, np.zeros(4), max_iter=1e5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим, чему равна ошибка на первых 50 итерациях стохастического градиентного спуска. Видим, что ошибка не обязательно уменьшается на каждой итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['ones']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10a4e2f90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEPCAYAAACHuClZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyURERNL2/zgag9jZje22AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10983cd10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(50), stoch_errors_by_iter[:50])\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь посмотрим на зависимость ошибки от номера итерации для $10^5$ итераций стохастического градиентного спуска. Видим, что алгоритм сходится.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10a4ced90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEPCAYAAABoekJnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npL4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10983c190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(len(stoch_errors_by_iter)), stoch_errors_by_iter)\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на вектор весов, к которому сошелся метод.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.91069256e+00,   2.78209808e+00,  -8.10462217e-03,\n",
       "         1.40190566e+01])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_grad_desc_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на среднеквадратичную ошибку на последней итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.78441258835276"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_errors_by_iter[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью градиентного спуска? Запишите ответ в файл '4.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.78441258841\n"
     ]
    }
   ],
   "source": [
    "answer4 = mserror(y, linear_prediction(X, stoch_grad_desc_weights))\n",
    "print(answer4)\n",
    "write_answer_to_file(answer4, '4.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответами к заданию будут текстовые файлы, полученные в ходе этого решения. Обратите внимание, что отправленные файлы не должны содержать пустую строку в конце. Данный нюанс является ограничением платформы Coursera. Мы работаем над исправлением этого ограничения.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
